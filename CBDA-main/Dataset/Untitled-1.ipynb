{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 (Updated)\n",
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "# Load your dataset\n",
    "df = pd.read_csv('cybertroll_dataset.csv')\n",
    "\n",
    "# Assuming your target variable is named 'annotation'\n",
    "X = df['content']  \n",
    "y = df['annotation']  \n",
    "\n",
    "# Data Cleaning and Preprocessing (example: converting to lowercase)\n",
    "X = X.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 (Updated)\n",
    "# Create TF-IDF and Count Vectorizers\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Transform the text data to TF-IDF and Count features\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test_tfidf, y_test, model_name):\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Precision-Recall Curve Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):  # Check if the model has predict_proba method\n",
    "        prob_pos = model.predict_proba(X_test_tfidf)[:, 1]\n",
    "    else:\n",
    "        prob_pos = model.decision_function(X_test_tfidf)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, prob_pos)\n",
    "    area_under_curve = auc(recall, precision)\n",
    "\n",
    "    plt.plot(recall, precision, color='darkorange', lw=2, label=f'Area under PR Curve = {area_under_curve:.2f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'{model_name} Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "\n",
    "    # Confusion Matrix Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Add space between plots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(f\"{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 (Updated)\n",
    "# Logistic Regression with TF-IDF\n",
    "lr_tfidf = LogisticRegression()\n",
    "lr_tfidf.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(lr_tfidf, X_test_tfidf, y_test, 'Logistic Regression (TF-IDF)')\n",
    "\n",
    "# Logistic Regression with CountVectorizer\n",
    "lr_count = LogisticRegression()\n",
    "lr_count.fit(X_train_count, y_train)\n",
    "evaluate_model(lr_count, X_test_count, y_test, 'Logistic Regression (Count)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 (Updated)\n",
    "# Random Forest with TF-IDF\n",
    "rf_tfidf = RandomForestClassifier(n_jobs=-1)\n",
    "rf_tfidf.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(rf_tfidf, X_test_tfidf, y_test, 'Random Forest (TF-IDF)')\n",
    "\n",
    "# Random Forest with CountVectorizer\n",
    "rf_count = RandomForestClassifier(n_jobs=-1)\n",
    "rf_count.fit(X_train_count, y_train)\n",
    "evaluate_model(rf_count, X_test_count, y_test, 'Random Forest (Count)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 (Updated)\n",
    "# XGBoost with TF-IDF\n",
    "xgboost_tfidf = xgb.XGBClassifier(n_jobs=-1)\n",
    "xgboost_tfidf.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(xgboost_tfidf, X_test_tfidf, y_test, 'XGBoost (TF-IDF)')\n",
    "\n",
    "# XGBoost with CountVectorizer\n",
    "xgboost_count = xgb.XGBClassifier(n_jobs=-1)\n",
    "xgboost_count.fit(X_train_count, y_train)\n",
    "evaluate_model(xgboost_count, X_test_count, y_test, 'XGBoost (Count)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 (Updated)\n",
    "# Naive Bayes with TF-IDF\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(nb_tfidf, X_test_tfidf, y_test, 'Naive Bayes (TF-IDF)')\n",
    "\n",
    "# Naive Bayes with CountVectorizer\n",
    "nb_count = MultinomialNB()\n",
    "nb_count.fit(X_train_count, y_train)\n",
    "evaluate_model(nb_count, X_test_count, y_test, 'Naive Bayes (Count)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 (Added)\n",
    "# Support Vector Classifier (SVC) with TF-IDF\n",
    "svc_tfidf = SVC()\n",
    "svc_tfidf.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(svc_tfidf, X_test_tfidf, y_test, 'Support Vector Classifier (TF-IDF)')\n",
    "\n",
    "# Support Vector Classifier (SVC) with CountVectorizer\n",
    "svc_count = SVC()\n",
    "svc_count.fit(X_train_count, y_train)\n",
    "evaluate_model(svc_count, X_test_count, y_test, 'Support Vector Classifier (Count)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 (Updated)\n",
    "# Decision Tree with TF-IDF\n",
    "dt_tfidf = DecisionTreeClassifier()\n",
    "dt_tfidf.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(dt_tfidf, X_test_tfidf, y_test, 'Decision Tree (TF-IDF)')\n",
    "\n",
    "# Decision Tree with CountVectorizer\n",
    "dt_count = DecisionTreeClassifier()\n",
    "dt_count.fit(X_train_count, y_train)\n",
    "evaluate_model(dt_count, X_test_count, y_test, 'Decision Tree (Count)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
